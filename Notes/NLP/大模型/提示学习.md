### Prompt Learning

​		标注数据很大程度上决定了 AI 算法上限，并且成本非常高，无论是**对比学习**（contrastive learning）还是**提示学习**（prompt learning）都着重解决**小样本学习**（few-shot learning）而提出，甚至在没有标注数据的情况下，也能让模型表现比较好的效果。

- Pre-trained Language Model 存在的问题

  - 预训练和精调任务的不一致
  - 数据稀缺性
    - 下游特定任务的标注数据量可能不太大。
    - 更多的实际情况是小样本、单样本甚至是零样本的场景。
    - 数据不够多时，再进行微调容易出现过拟合的情况。 

  - 预训练模型的参数体量越来越大
    - 较高的算力计算成本（训练和微调时要更新所有的参数，就会有较高的算力要求）
      - 较大的存储空间要求（实际应用时，下游每个特定的任务都要对一个大模型进行一次微调（复制））
    - 每个任务都要对大模型进行一次复制，会造成部署资源的浪费

​	针对预训练模型存在的这些问题，解决方案就是 Prompt-Based Learning。

**Prompt Learning 的本质：**将所有下游任务统一成预训练任务；**以特定的模板，将下游任务的数据转成自然语言形式**，充分挖掘预训练模型本身的能力。**Prompt/Instruction Tuning：**通过 Prompt 统一各种任务，在众多类型任务的标注数据上精调语言模型，处理未见任务；

#### （hard）Prompt Tuning：

- GPT3: in-context learning

  - in-context learning：

    - zero-shot learning：不允许输入任何示例（例题），只允许输入一则任务说明（题型说明）
    - one-shot learning：只允许输入一条示例和一则任务说明
    - few-shot learning：输入数条示例和一则任务说明

    ![image-20230223142914152](C:\Users\千江映月\AppData\Roaming\Typora\typora-user-images\image-20230223142914152.png)

##### PET

PET（Pattern Exploiting Training） 是一种较为经典的提示学习方法，和之前的举例一样，将问题建模成一个完形填空问题，然后优化最终的输出词。**虽然 PET 也是在优化整个模型的参数**，但是相比于传统的 Finetuning 方法，**对数据量需求更少**。

- Prompt Template：针对一个给定的任务，手动设计自然语言输入

- PLM：执行语言建模，掩码语言模型或是自回归模型都可以

- Verbalizer：完成从词汇表中 token 到 任务标签的映射

##### LM-BFF

- LM-BFF（Better Few-shot Fine-tuning of Language Models）idea：prompt + demonstration（示例）for few-shot learning

  ![image-20230306162507193](C:\Users\千江映月\AppData\Roaming\Typora\typora-user-images\image-20230306162507193.png)

- template generation

discrete/hard prompts，也就是人工设计的prompts存在的问题：人认为合理的prompt并不一定有效；预训练模型对于人工选取的prompt非常敏感，稍加改动可能效果差异巨大。，

#### （soft）Prompt Tuning

##### P-tuning

不再人工设计硬模板，而是在输入端直接插入若干可被优化的 Pseudo Prompt Tokens，通过学习对应的嵌入表示来寻找效果较好的prompt：

![image-20230306164054558](C:\Users\千江映月\AppData\Roaming\Typora\typora-user-images\image-20230306164054558.png)

Discrete Prompt：该方法为基于token的prompt，对应的输入为： “The captital of Britain is [MASK]”

P-tuning：该方法只保留了部分关键字 token 信息，其余的token都改为模型可以学习的向量表示，对应的输入为: “h_0 , h_1, ... h_i, captital, Britain, h_(i+1), ..., h_m [MASK]”。

##### Prefix-tuning

[代码使用指南](https://huggingface.co/docs/peft/task_guides/seq2seq-prefix-tuning)

Prefix-tuning keeps the language model parameters frozen and optimizes a small continuous task-specific vector called the prefix. In prefix-tuning, the prefix is a set of free parameters that are trained along with the language model. The goal of prefix-tuning is to find a context that steers the language model toward generating text that solves a particular task.

When using prefix tuning, only the prefixes are updated, while the rest of the layers are fixed and not updated.

Prefix-tuning 训练期间冻结 transformer 的参数，只更新 Prefix 的参数。只需要存储大型 transformer 的一个副本和学习到的特定于任务的前缀权重即可，为每个附加任务产生非常小的开销。

![image-20230306164249523](C:\Users\千江映月\AppData\Roaming\Typora\typora-user-images\image-20230306164249523.png)





![image-20230704122258614](C:\Users\千江映月\AppData\Roaming\Typora\typora-user-images\image-20230704122258614.png)

##### soft prompt-tuning

![image-20230306164600704](C:\Users\千江映月\AppData\Roaming\Typora\typora-user-images\image-20230306164600704.png)

#### Instruction tuning

![image-20230306165021263](C:\Users\千江映月\AppData\Roaming\Typora\typora-user-images\image-20230306165021263.png)

- FLAN：Fine-tuned LANguage Models

  ![image-20230306165230607](C:\Users\千江映月\AppData\Roaming\Typora\typora-user-images\image-20230306165230607.png)

​	这种学习方法的主要思想是：通过在B、C、D、E、……任务上对任务描述进行学习（微调）之后，从而让模型在没见过的任务A进行推断，从而使得模型可以更好地理解任务的描述。触类旁通的意思。使用 instruction 方式可以和 prompt 方式结合对预训练模型进行精调，并能取得更好的效果（前提是模型的size 足够大，不然就过拟合在训练数据上）。



