[综述](https://zhuanlan.zhihu.com/p/326302618)

### 实体抽取类型：

- 嵌套实体识别：如组织机构名“武汉大学”中的“武汉”也是地名。
- 非连续命名实体识别：如“发动机掉速，且黑烟”中需要识别出“发动机掉速、发动机冒黑烟”，两个实体。
- 类型易混淆实体：如“卡滞”是现象词还是故障词，也就是一个词可能对应两个、甚至多个实体类型。

### 实体抽取模型

- 按照实体抽取输入层划分:
  - 基于字符表示的模型
  - 基于词表示的模型 
  - 基于字词混合表示的模型
- 按照处理任务划分：
  - 序列标注任务：BiLSTM + CRF（CRF缺陷，序列较长或是实体类型较多时，速度较慢。）
  - 序列元素分类任务：BERT + SoftMax
  - 序列生成任务：基于RNN逐个生成句子中词的分类标签，并将前一个词的预测标签作为下一个词标签预测的输入。











```
class NewMultiHeadedAttention(nn.Module):
    def __init__(self, hidden_size, heads_num, dropout):
        super(NewMultiHeadedAttention, self).__init__()
        self.hidden_size = hidden_size
        self.heads_num = heads_num
        self.per_head_size = hidden_size // heads_num
        self.tokeys = nn.Linear(self.per_head_size, self.per_head_size, bias=False)
        self.toqueries = nn.Linear(self.per_head_size, self.per_head_size, bias=False)
        self.tovalues = nn.Linear(self.per_head_size, self.per_head_size, bias=False)



        self.dropout = nn.Dropout(dropout)
        self.final_linear = nn.Linear(hidden_size, hidden_size)

    def forward(self, hiddens, mask):
        batch_size, seq_len, hidden_size = hiddens.size()
        hiddens = hiddens.view(batch_size, seq_len, self.heads_num, self.per_head_size)
        keys = self.tokeys(hiddens)
        queries = self.toqueries(hiddens)
        values = self.tovalues(hiddens)
        keys = keys.transpose(1, 2).contiguous().view(batch_size * self.heads_num, seq_len,self.per_head_size )
        queries = queries.transpose(1, 2).contiguous().view(batch_size * self.heads_num, seq_len,self.per_head_size )
        values = values.transpose(1, 2).contiguous().view(batch_size * self.heads_num, seq_len,self.per_head_size)

        queries = queries / (hidden_size ** (1 / 4))
        keys = keys / (hidden_size ** (1 / 4))
        dot = torch.bmm(queries, keys.transpose(1, 2))
        if mask:
            mask = mask.unsqueeze(1).repeat(1, 128, 1).unsqueeze(1)
            dot = dot.view(batch_size, self.heads_num,seq_len, self.per_head_size) + (1.0 - mask.float()) * -10000.0
            dot = dot.view(batch_size * self.heads_num, seq_len,self.per_head_size)
        dot = torch.softmax(dot, dim=2)
        out = torch.bmm(dot, values).view(batch_size, self.heads_num,seq_len, self.per_head_size)

        # swap h, t back, unify heads
        out = out.transpose(1, 2).contiguous().view(batch_size, seq_len, hidden_size)
        output = self.final_linear(self.dropout(out))
        return output

```

