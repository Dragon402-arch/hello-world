- [讲解](https://stackabuse.com/python-for-nlp-multi-label-text-classification-with-keras/)

- **Multi-class classification VS  Multi-label classification**

  At this point, it is important to explain the difference between a multi-class classification problem and a multi-label classification. In multi-class classification problem, an instance or a record can belong to one and only one of the multiple output classes. On the other hand in multi-label classification problems, an instance can have multiple outputs at the same time.

  

- **Creating Multi-label Text Classification Models**

  There are two ways to create multi-label classification models: **Using single dense output layer and using multiple dense output layers.**There are two ways to create multi-label classification models: Using single dense output layer and using multiple dense output layers.

  In the first approach, we can use a single dense layer with six outputs with a sigmoid activation functions and binary cross entropy loss functions. Each neuron in the output dense layer will represent one of the six output labels. The sigmoid activation function will return a value between 0 and 1 for each neuron. If any neuron's output value is greater than 0.5, it is assumed that the comment belongs to the class represented by that particular neuron.

  In the second approach we will create one dense output layer for each label. We will have a total of 6 dense layers in the output. Each layer will have its own sigmoid function.

  - **Multi-lable Text Classification Model with Single Output Layer**

    - Using single dense output layer（推荐使用）
    - 一个线性层 + sigmoid激活函数 + binary cross entropy loss functions.
    - 若总共六个类别，则该线性层映射到6维。

  - **Multi-lable Text Classification Model with Multiple Output Layers**

    - Using multiple dense output layers

    - 多个线性层 + sigmoid激活函数 + binary cross entropy loss functions.

    - 若总共六个类别，就设置六个线性层（每个对应一个标签），每个线性层都映射到1维

    - 一般而言，该方案模型复杂度较高，容易过拟合，在测试集上的性能较差。

      

- **Techniques for Solving a Multi-Label classification problem**

  - [讲解](https://www.analyticsvidhya.com/blog/2017/08/introduction-to-multi-label-classification/)

  - Problem Transformation

    - 转化为多分类问题，使用训练数据中所有的标签组合训练一个多分类器

      - 如0/1/2三个标签，则标签组合有：

        （0）、（1）、（2）、（0/1）、（0/2）、（0/3）、（1/2）、（1/3）、（2/3）、（1/2/3）

      - 缺点：随着标签数量的增加，类别数量会非常大，准确率下降。

    - 多标签转化为单标签，每个标签对应一个二分类问题。

      ![image-20220125213928354](C:\Users\千江映月\AppData\Roaming\Typora\typora-user-images\image-20220125213928354.png)

      缺点：独立处理每个标签，没有考虑标签之间的相关性。

      

    - The first classifier is trained just on the input data and then each next classifier is trained on the input space and all the previous classifiers in the chain. 

      ![image-20220125214529628](C:\Users\千江映月\AppData\Roaming\Typora\typora-user-images\image-20220125214529628.png)

      优点 ：考虑了标签之间的相关性

      

    - 

  - Adapted Algorithm 

  - Ensemble approaches 

- 

  

