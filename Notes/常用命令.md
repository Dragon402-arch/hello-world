- 传输文件

  ```shell
  # 本地传输至远程
  sudo scp -P 22 /home/chinaoly/lis/eventTrain/SPN4EE_V1/final_trained_event_model.pth chinaoly@192.168.51.51:/home/chinaoly/lis  
  
  sudo scp -P 22 new_final_trained_event_model.pth chinaoly@192.168.51.51:/home/chinaoly/lis/intentSearchV1/
  
   
   
   
  sudo scp -P 22 -r /date/pretrained_models/chatglm2-6b/ root@172.16.13.186:/root/algProjects/
  sudo scp -P 22 event_extraction-1.0.0-py3.7-x86.tar chinaoly@192.168.51.59:/data1/智能中心算法镜像包/搜索事件抽取算法/
  
   
  sudo scp -P 22  /data1/智能中心算法镜像包/算子推荐算法/operator_recommend-1.1.0-py3.7-x86.tar chinaoly@192.168.51.51:/home/chinaoly/lis
  
  
  148.144.31.224 /root/algProjects/search1.1
  
  
  
  fp4, nf4
  
  
  sftp -P 29880 iluvatar_mr@iftp.iluvatar.com.cn
  
  
  
  
  conda config --add channels https://mirrors.ustc.edu.cn/anaconda/pkgs/free/
  conda config --add channels http://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/free/
  conda config --add channels http://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/
  conda config --add channels http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/
  conda config --set show_channel_urls yes
  
  
  
  ```

- 区别 ZAAI/gUB4v@*m

  数据盘功能

  模型里面集成了网络搜索 并将搜索召回的信息整合到对话流程中，解决了大模型获取实时信息的问题。现在的大模型里面并不能获取最新的信息，要依靠外挂一个向量库给他提供上下文，相当于开卷考试，而webGLM就相当于拿着手机考试了，不过他目前只支持谷歌的搜索api。

  ```python
  
  
  
  Parameter at index 55 has been marked as ready twice. This means that multiple autograd engine  hooks have fired for this particular parameter during this iteration. You can set the environment variable TORCH_DISTRIBUTED_DEBUG to either INFO or DETAIL to print parameter names for further debugging.
  
  
  RuntimeError: Expected to mark a variable ready only once. This error is caused by one of the following reasons: 1) Use of a module parameter outside the `forward` function. Please make sure model parameters are not shared across multiple concurrent forward-backward passes. or try to use _set_static_graph() as a workaround if this module graph does not change during training loop.2) Reused parameters in multiple reentrant backward passes. For example, if you use multiple `checkpoint` functions to wrap the same part of your model, it would result in the same set of parameters been used by different reentrant backward passes multiple times, and hence marking a variable ready multiple times. DDP does not support such use cases in default. You can try to use _set_static_graph() as a workaround if your module graph does not change over iterations.
  Parameter at index 55 with name base_model.model.transformer.layers.27.attention.query_key_value.lora_B.weight has been marked as ready twice. This means that multiple autograd engine  hooks have fired for this particular parameter during this iteration.
  
  
  
   GLMBlock(
              (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
              (attention): SelfAttention(
                (rotary_emb): RotaryEmbedding()
                (query_key_value): MergedLinear(
                  in_features=4096, out_features=12288, bias=True
                  (lora_dropout): Dropout(p=0.1, inplace=False)
                  (lora_A): Linear(in_features=4096, out_features=16, bias=False)
                  (lora_B): Conv1d(16, 8192, kernel_size=(1,), stride=(1,), groups=2, bias=False)
                )
                (dense): Linear(in_features=4096, out_features=4096, bias=True)
              )
              (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
              (mlp): GLU(
                (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)
                (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)
              )
            )
  base_model.model.transformer.layers.27.attention.query_key_value.lora_A.weight torch.Size([16, 4096])
  base_model.model.transformer.layers.27.attention.query_key_value.lora_B.weight torch.Size([8192, 8, 1])
  
  不支持梯度检查点，强行引入可以降低显存占用，
  
  
  
  
      
  conda install paddlepaddle-gpu==2.4.2 cudatoolkit=11.6 -c https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/Paddle/ -c conda-forge
  
  
  ```

  

- OCR

  - Text detection 文本框识别（图像分割）
  - Text Direction Classification 文本框方向分类
  - Text recoginition 文本框内容识别

- 开发方向

  - 串并案
  - 警情标签体系建设
  - 人案关联
  - 案件要素关系抽取（文档级关系抽取）

- 后台运行

  ```shell
  nohup python -u intentsearch_router.py > run.log 2>&1 &
  
  
  nohup python -u Knowledgebase_router.py  > run.log 2>&1 &
  nohup python -u router.py  > router.py.log 2>&1 &
  
  184
  nohup python -W ignore -u run.py --gpu_devices 0 1 2 3 > run.log 2>&1 &
  
  nohup python -u ddp_run.py > run.log 2>&1 &
  
  nohup python -u final_router.py  > run.log 2>&1 &
  
  nohup python -u web_demo.py  > run.log 2>&1 &
  iptables -D INPUT 
  
  nohup python -u example.py > run.log 2>&1 &
  # 查看后几行
  tail -f train.log
  
  
  nohup python -u main.py > run.log 2>&1 &
  nohup python -u import_data_to_es.py > run.log 2>&1 &
  
  
  nohup ./my-shell-script.sh &
  
  
  
  CUDA_VISIBLE_DEVICES=2,1,0 nohup python -m torch.distributed.launch --nproc_per_node 3 --master_addr 127.0.0.2 --master_port 29505 run_long_doc2cls.py --batch_size 48 --train_epochs 10 --model_id C5F02CA2328692FA090390C34C7AD0C7 --gpu_num 3 --model_path /home/chinaoly/lis/xinfang/multi_level/model_save_dir/ --max_len 128 --model_class single --pretrained_dir /data1/Doc2EDAG_test/.pytorch_pretrained_bert --label_path /home/chinaoly/lis/xinfang/multi_level/data_dir/label.json --data_dir /home/chinaoly/lis/xinfang/multi_level/data_dir/ --rabbitmq_username rabbitadmin --rabbitmq_password 123456 --rabbitmq_host 172.16.100.135 --rabbitmq_port 5672 --rabbitmq_exchange ex_nlp --rabbitmq_queue nlp > run.log 2>&1 &
  
  
  
  
  CUDA_VISIBLE_DEVICES=2,1,0 nohup python -m torch.distributed.launch --nproc_per_node 3 --master_addr 127.0.0.2 --master_port 29505 run_long_doc2cls.py --batch_size 48 --train_epochs 10 --model_id C5F02CA2328692FA090390C34C7AD0C7 --gpu_num 3 --model_path /home/chinaoly/lis/xinfang/intent_cls/model_save_dir/ --max_len 128 --model_class single --pretrained_dir /data1/Doc2EDAG_test/.pytorch_pretrained_bert --label_path /home/chinaoly/lis/xinfang/intent_cls/data_dir/label.json --data_dir /home/chinaoly/lis/xinfang/intent_cls/data_dir/ --rabbitmq_username rabbitadmin --rabbitmq_password 123456 --rabbitmq_host 172.16.100.135 --rabbitmq_port 5672 --rabbitmq_exchange ex_nlp --rabbitmq_queue nlp > run.log 2>&1 &
  
  CUDA_VISIBLE_DEVICES=2,1,0 python -m torch.distributed.launch --nproc_per_node 3 --master_addr 127.0.0.2 --master_port 29505 run_long_doc2cls.py --batch_size 48 --train_epochs 10 --model_id C5F02CA2328692FA090390C34C7AD0C7 --gpu_num 3 --model_path /home/chinaoly/lis/xinfang/intent_cls_test/model_save_dir/ --max_len 128 --model_class single --pretrained_dir /data1/Doc2EDAG_test/.pytorch_pretrained_bert --label_path /home/chinaoly/lis/xinfang/intent_cls_test/data_dir/label.json --data_dir /home/chinaoly/lis/xinfang/intent_cls_test/data_dir/ --rabbitmq_username rabbitadmin --rabbitmq_password 123456 --rabbitmq_host 172.16.100.135 --rabbitmq_port 5672 --rabbitmq_exchange ex_nlp --rabbitmq_queue nlp
  
  
  
  
  
  # 
  CUDA_VISIBLE_DEVICES=2,1,0 python -m torch.distributed.launch --nproc_per_node 3 --master_addr 127.0.0.2 --master_port 29505 run_long_doc2cls.py --batch_size 48 --train_epochs 10 --model_id C5F02CA2328692FA090390C34C7AD0C7 --gpu_num 3 --model_path /home/chinaoly/lis/xinfang/multi_level/model_save_dir/ --max_len 128 --model_class single --pretrained_dir /data1/Doc2EDAG_test/.pytorch_pretrained_bert --label_path /home/chinaoly/lis/xinfang/multi_level/data_dir/label.json --data_dir /home/chinaoly/lis/xinfang/multi_level/data_dir/ --rabbitmq_username rabbitadmin --rabbitmq_password 123456 --rabbitmq_host 172.16.100.135 --rabbitmq_port 5672 --rabbitmq_exchange ex_nlp --rabbitmq_queue nlp 
  
  
  # 预测
  python run_long_doc2cls.py --model_id C5F02CA2328692FA090390C34C7AD0C7 --model_path /home/chinaoly/lis/xinfang/multi_level/model_save_dir/ --max_len 128 --model_class single --pretrained_dir /data1/Doc2EDAG_test/.pytorch_pretrained_bert --label_path /home/chinaoly/lis/xinfang/multi_level/data_dir/label.json --data_dir /home/chinaoly/lis/xinfang/multi_level/data_dir/ --rabbitmq_username rabbitadmin --rabbitmq_password 123456 --rabbitmq_host 172.16.100.135 --rabbitmq_port 5672 --rabbitmq_exchange ex_nlp --rabbitmq_queue nlp --do_task do_predict --predict_file_name /home/chinaoly/lis/xinfang/multi_level/data_dir/predict.json 
  
  
  ```

  GPlinker DUEe UIE

- 服务器

  | IP             | port | username/password |
  | -------------- | ---- | ----------------- |
  | 172.16.150.236 | 22   | root/Chinaoly@123 |
  | 172.16.150.212 | 22   | root/Chinaoly@123 |
  | 192.168.51.58  | 22   | %TGB5tgb8ik,      |
  | 192.168.51.59  | 22   | %TGB5tgb9ol.      |
  | 192.168.51.51  | 22   | %TGB5tgb1qaz      |




- 模型

  - Efficient GlobalPointer Torch ：https://github.com/xhw205/Efficient-GlobalPointer-torch

  - GlobalPointer Torch：https://github.com/xhw205/GlobalPointer_torch 实体抽取

  - GPlinker Torch：https://github.com/xhw205/GPLinker_torch 关系抽取

  



- Character AI：主打情感陪伴
- 

- 领域专业知识不足：专业知识的增量预训练与指令微调
- 生成内容不可控：进行高质量知识注入、价值观对其、安全围栏等特定训练
- 生成内容不可信：使用稠密向量搜索引擎技术，对生成结果进行事实性核查
- 知识更新不及时：增量微调 + 外挂本地知识库









