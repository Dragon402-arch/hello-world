#### 集群环境配置

- 构建集群

  多个节点 node 相互连接可以构成集群 cluster，节点之间可以相互通信。

- 域名映射

  首先，域名，也就是常说的主机名，英文为 HOSTNAME。一台新装机的Linux服务器（物理机或虚拟机），其默认的HOSTNAME为 `localhost.localdomain`，使用命令 `cat /etc/hostname` 即可进行验证。默认的主机名因为不具有唯一性，因此在构建集群时需要对其进行修改，可以执行如下命令：

  ```shell
  chianoly@chinaoly$ sudo vim /etc/hostname
  
  # 将 localhost.localdomain 删掉
  # 新增 chinaoly31 作为主机名
  
  # 写法一
  chinaoly31
  
  # 写法二
  HOSTNAME=chinaoly31
  
  # 保存退出
  ```

  - 注意：修改完域名之后不会立即生效，需要重启 `reboot` 一下之后修改才会生效。

  - 按照上述操作步骤，分别修改每个节点的主机名，如果已经修改过了，则不需要修改。
  - 修改前终端为 `lis@localhost`，修改后终端变为 `lis@chinaoly31`

  其次，添加域名映射，也就是将host和hostname的对应关系添加到每个节点上，具体的操作步骤如下：

  ```shell
  chianoly@chinaoly$ sudo vim /etc/hosts
  
  # 文件中原有的映射以及内容不用修改，只进行追加即可。
  192.168.51.51   chinaoly51
  192.168.51.59   chinaoly59
  172.16.100.31   chinaoly31
  
  # 保存退出
  ```

  - 按照上述操作步骤，分别修改每个节点上所有节点的IP和主机名的对应关系。

- 免密登录

  集群的节点之间通过SSH的方式进行相互连接，节点之间进行相互通信时必须使用password，通过几步操作可以实现节点之间的免密登录，手动操作步骤如下：

  ```shell
  chianoly@chinaoly$ ssh-keygen -t rsa
  
  # 一直使用 Enter 键即可在当前用户的目录下生成一个.ssh文件夹，其中包含如下几个文件。
  	id_rsa   
  	id_rsa.pub # 需要将该文件内容复制到其他节点的authorized_keys文件中。
  	known_hosts
  	authorized_keys # 若不存在，则需要自行创建
  
  ```

  - 需要把集群中每个节点的  `id_rsa.pub` 文件的内容都复制到 `authorized_keys` 文件中。

  - 快捷命令操作：[视频讲解](https://www.bilibili.com/video/BV1C5411c7Qv?p=5&vd_source=390d16c51af19211c9d56a848f7c3fee)

    ```shell
    # 在 chinaoly51 节点上操作
    
    # 将自身秘钥传给 chinaoly59 和 chinaoly31
    chianoly@chinaoly$ ssh-copy-id chinaoly59 
    chianoly@chinaoly$ ssh-copy-id chinaoly31
    
    
    # 在 chinaoly59 节点上操作
    
    # 将自身秘钥传给 chinaoly51 和 chinaoly31
    chianoly@chinaoly$ ssh-copy-id chinaoly51 
    chianoly@chinaoly$ ssh-copy-id chinaoly31
    
    
    # 在 chinaoly31 节点上操作
    
    # 将自身秘钥传给 chinaoly51 和 chinaoly59
    chianoly@chinaoly$ ssh-copy-id chinaoly51 
    chianoly@chinaoly$ ssh-copy-id chinaoly59
    
    ```

  - 验证

    - 验证方式一

      ```shell
      # 在chinaoly59服务器上登录chianoly51节点，
      chianoly@chinaoly$ ssh chianoly51
      
      #登录成功则表示配置成功
      
      # 退出登录，回到chinaoly59服务器
      exit
      ```

    - 验证方式二

      ```shell
      # 测试是否相互 ping 得通, 在chinaoly59服务器上测试
      
      ping chianoly51 -c 3   # 只ping 3次，否则要按 Ctrl+c 中断
      ping chianoly31 -c 3
      ```




#### 运行环境配置

- CUDA版本一致（Linux系统可以同时安装多个CUDA版本），安装时都需要和系统版本适配。

  - **NVIDIA Driver**：安装驱动

  - **CUDA Toolkit**：

    - [11.3下载地址](https://developer.nvidia.com/cuda-10.2-download-archive)
    - [10.2下载地址](https://developer.nvidia.com/cuda-10.2-download-archive)

    ![image-20230421161001929](C:\Users\千江映月\AppData\Roaming\Typora\typora-user-images\image-20230421161001929.png)

    此处应该选择 Continue，保留原有CUDA的驱动。

    安装完后输出日志：

    ```shell
    ===========
    = Summary =
    ===========
    
    Driver:   Not Selected
    Toolkit:  Installed in /usr/local/cuda-11.3/
    Samples:  Installed in /home/chinaoly/, but missing recommended libraries
    
    Please make sure that
     -   PATH includes /usr/local/cuda-11.3/bin
     -   LD_LIBRARY_PATH includes /usr/local/cuda-11.3/lib64, or, add /usr/local/cuda-11.3/lib64 to /etc/ld.so.conf and run ldconfig as root
    
    To uninstall the CUDA Toolkit, run cuda-uninstaller in /usr/local/cuda-11.3/bin
    ***WARNING: Incomplete installation! This installation did not install the CUDA Driver. A driver of version at least 465.00 is required for CUDA 11.3 functionality to work.
    To install the driver using this installer, run the following command, replacing <CudaInstaller> with the name of this run file:
        sudo <CudaInstaller>.run --silent --driver
    
    Logfile is /var/log/cuda-installer.log
    
    ```

  - **cuDNN**：[下载地址](https://developer.nvidia.com/rdp/cudnn-archive)

  - 查看CUDA版本命令：`nvcc --version`

  - 安装步骤教程：[教程](https://www.cnblogs.com/smileglaze/p/16826946.html)

- PyTorch版本一致

- **NCCL（ NVIDIA Collective Communication Library）**版本一致

  [NCCL下载地址](https://developer.nvidia.com/nccl/nccl-legacy-downloads)

  ```python
  # 查看 nccl版本
  import torch
  torch.cuda.nccl.version()

- 启动命令

  在每个节点上都执行 `sh ./run.sh`，分别输入即可，整个程序会在所有节点都启动了之后才会向下运行。因为启动器会等到所有的节点都同步（都输入了相同的命令）之后才会启动。

- 问题避免

  1. 确保所有GPU和节点都使用相同的PyTorch版本，并且版本号相同。
  2. 在运行DDP脚本之前，请确保在所有节点上设置了相同的环境变量，例如PYTHONPATH，LD_LIBRARY_PATH等。
  3. 尝试减少批处理大小或者减少训练时使用的GPU数量。过大的批次或者过多的GPU可能会导致内存问题。
  4. 如果您的代码使用PyTorch分布式通信包（如torch.distributed），请确保正确处理通信异常。例如，如果您的训练过程在某个节点上中断，则需要确保在其他节点上等待该节点返回结果，或者重新启动该节点。

  - 想问一下在不同的机器使用ddp启动的时候是每个机器都启动一下，但是依赖外部分配资源的话没有办法直接访问每个机器那这个问题怎么解决呢
    - 试一下horovod？是类似于mpi的启动方式，一台机器调动其他机器
  - pytorch 对多线程/进程推理不友好, 会发现没有加速效果 (具体可以用 nv nsight debug 试试, 估计大概率是 nccl 通信那里的处理有问题), 如果只是推理, 建议转换到 openvino/onnxruntime/tensorrt 后再放到子线程/进程推理, 提速明显

#### 多机多卡训练BUG记录

- NCCL导致的报错，报错信息如下：

  ```shell
  Traceback (most recent call last):
    File "review_cls_run.py", line 86, in <module>
      trainer.train()
    File "/data1/conda/envs/finetune/lib/python3.7/site-packages/transformers/trainer.py", line 1666, in train
      ignore_keys_for_eval=ignore_keys_for_eval,
    File "/data1/conda/envs/finetune/lib/python3.7/site-packages/transformers/trainer.py", line 1749, in _inner_training_loop
      model = self._wrap_model(self.model_wrapped)
    File "/data1/conda/envs/finetune/lib/python3.7/site-packages/transformers/trainer.py", line 1573, in _wrap_model
      **kwargs,
    File "/data1/conda/envs/finetune/lib/python3.7/site-packages/torch/nn/parallel/distributed.py", line 646, in __init__
      _verify_param_shape_across_processes(self.process_group, parameters)
    File "/data1/conda/envs/finetune/lib/python3.7/site-packages/torch/distributed/utils.py", line 89, in _verify_param_shape_across_processes
      return dist._verify_params_across_processes(process_group, tensors, logger)
  RuntimeError: NCCL error in: /opt/conda/conda-bld/pytorch_1659484772347/work/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1191, unhandled system error, NCCL version 2.10.3
  ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. It can be also caused by unexpected exit of a remote peer, you can check NCCL warnings for failure reason and see if there is connection closure by a peer.
  ```

  报错重点信息：

  RuntimeError: NCCL error in: /opt/conda/conda-bld/pytorch_1659484772347/work/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1191, unhandled system error, NCCL version 2.10.3
  ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 

  解决方案：

  ```shell
  export NCCL_IB_DISABLE=1
  export NCCL_SOCKET_IFNAME=eno1
  ```

  这是因为集群环境上使用CUDA设备，因此使用NCCL backend。然后因为没有InfiniBand（IB）连接，因此需要设置如下环境变量来禁用IB连接而使用以太网。将NCCL_IB_DISABLE设置为1来禁止使用InfiniBand，转而使用 IP。

  

- 训练速度比较慢，远慢于单机多卡，网线直通可能会快点，路由器带宽限制了速度。