- torch.where

  ```python
  x = torch.randn(3, 2)
  y = torch.ones(3, 2)
  >>> torch.where(x > 0, x, y)
  tensor([[ 1.0000,  0.3139],
          [ 0.3898,  1.0000],
          [ 0.0478,  1.0000]])
  >>> torch.where(x > 0, x, 0.)
  tensor([[1.0779, 0.0383],
          [0.0000, 0.0000]], dtype=torch.float64)
  ```

  

- torch.tril()：对角线及以下

- torch.triu()：对角线及以上

- torch.eye()：对角线

  

- torch.finfo(self.dtype): float info

  - torch.finfo(self.dtype).max
  - torch.finfo(self.dtype).min

- torch.iinfo(self.dtype):  int info

  

- torch.numel(): Returns the total *number* of *elements* in the tensor

  

- torch.squeeze()

- torch.unsqueeze()

  

- torch.cat()
- torch.stack()



- torch.reshape()

- torch.view()

  

- 符号表示的运算

  - `* ` 表示矩阵逐元素乘积
  - `@` 表示矩阵乘法

- 残差连接

  Residual connections are used to help address the problem of vanishing gradients, which can occur when the gradients of the network become very small and it becomes difficult for the network to learn effectively. By allowing the information to bypass some of the layers, the residual connections can help to maintain the magnitude of the gradients as the information flows through the network, making it easier for the network to train.

