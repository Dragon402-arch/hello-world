#### 库表操作

- 公司hive连接

  ```shell
   kinit -kt /opt/hive.keytab hive/cbp5.chinaoly.com@CHINAOLY.COM
   
   beeline -u "jdbc:hive2://cbp5.chinaoly.com:10000/;principal=hive/cbp5.chinaoly.com@CHINAOLY.COM"
   
   
   select concat("","涉黄","","涉赌","")
  ```

- 数据库

  ```sql
  -- 创建数据库
  
  create database IF NOT EXISTS testdb;
  
  -- 删除数据库
  DROP DATABASE IF EXISTS testdb;
  
  -- 强制删除数据库
  
  drop database if exists testdb cascade;
  
  ```

- 数据表

  - 建表

    - 方式一

      ```sql
      drop table if exists testdb.employee;
      CREATE TABLE IF NOT EXISTS testdb.employee ( eid int, name String,
      salary int, age int)
      COMMENT "员工信息"
      -- PARTITIONED BY ( fq_day string COMMENT '分区天') PARTITIONED BY (city string,sdate string)
      ROW FORMAT DELIMITED  --分隔符设置开始语句
      FIELDS TERMINATED BY "\t"
      LINES TERMINATED BY "\n"
      STORED AS TEXTFILE;
      ```

      - Hive 表存储文件格式:**TextFile**（默认的存储格式）、**Parquet**、**SequenceFile**、**RCFile**、**AVRO**、**ORC**

    - 方式二：建表并导入数据

      ```sql
      drop table if exists testdb.tmp_employee;
      create table testdb.tmp_employee as
      select * from testdb.employee
      ```

      - as只会复制字段以及字段值到新的表中
      - 使用as创建的表，并不会带原表的分区（分区丢失），包括一些字段的约束等。
      - 新表中会将原表的分区当作字段出现在新表中。

    - 方式三：允许用户复制现有的表结构，但是不复制数据，与as区别。

      ```sql
      create table testdb.tmp_employee like testdb.employee;
      ```

      

  - 删表

    ```sql
    -- 删除表数据，保留表结构，也叫清空表
    truncate table if exists employee;
    
    # 清空表
    insert overwrite table employee select * from employee where 1=0; 
    
    -- 删除表
    drop table if exists employee;
    
    -- 删除指定分区
    alter table employee drop partition (stat_year_month>='2018-01');
    alter table employee drop if exists partition(dt="20190909");
    
    -- 添加分区
    alter table employee if not exists add partition (p_hour='2017113003', p_city='573', p_loctype='MHA');
    
    -- 按条件删除数据
    insert overwrite table employee_table select * from employee_table where id>'180203a15f';
    
    ```

  - 导入数据

    - 导入类型：

      - 追加导入：into

        ```sql
        insert into table stuent1 select * from student2;
        ```

      - 覆盖导入：overwrite（轻易不要使用）

        ```sql
        insert overwrite table stuent1 select * from student2;
        ```

    - 方式一：

      ```sql
      # 不带分区
      insert into table testdb.employee Values ("1205","马明",3500,24),("1206","赵敏",4800,27);
      
      # 带有分区
      insert into table testdb.employee partition(dt="20221027") Values ("1205","马明",3500,24),("1206","赵敏",4800,27);
      ```

    - 方式二：

      ```sql
      # 带有分区
      insert into table testdb.employee partition(dt="20221027")
      select * from testdb.employee;
      
      # 不带分区
      insert into table testdb.employee
      select * from testdb.employee;
      ```

    - 方式三：

      ```sql
      -- 先将本地文件上传到hdfs系统中。
      hdfs dfs -put /home/flink/hive_test/employee.txt /employee.txt
      
      # 在已经登陆beeline的窗口加载数据
      LOAD DATA INPATH '/employee.txt' OVERWRITE INTO TABLE employee;
      
      LOAD DATA INPATH '/employee.txt' OVERWRITE INTO TABLE employee partition(country='china',city='nanjing')；
      
      
      # 必须在HiveServer2服务器节点操作 
      LOAD DATA LOCAL INPATH '/home/flink/hive_test/employee.txt' OVERWRITE INTO TABLE employee;
      ```

      - Hive使用`LOAD DATA LOCAL INPATH`时，数据文件必须与HiveServer2服务在同一个节点，否则会报“Invalid path ‘/path’:No files matching path file”异常
      - 可以使用LOAD DATA方式加载HDFS上的数据，就不会有这样的限制
      - **向分区插入数据时，分区值作为一个字段值进行存储。**

    - 

#### 数据类型

- 数值类型

  |   类型   | 长度  |             备注              |
  | :------: | :---: | :---------------------------: |
  | TINYINT  | 1字节 |       有符号整型，如20        |
  | SMALLINT | 2字节 |       有符号整型，如300       |
  |   INT    | 4字节 |      有符号整型，如9999       |
  |  BIGINT  | 8字节 |          有符号整型           |
  |  FLOAT   | 4字节 | 有符号单精度浮点数，如3.14159 |
  |  DOUBLE  | 8字节 |      有符号双精度浮点数       |
  | DECIMAL  |  --   |   可带小数的精确数字字符串    |

- 时间类型

  |   类型    | 长度 |                    备注                     |
  | :-------: | :--: | :-----------------------------------------: |
  | TIMESTAMP |  --  | UTC时间，时间戳：yyyy-mm-dd hh:mm:ss[.f...] |
  |   DATE    |  --  |         日期，内容格式：YYYY­MM­DD          |

- 字符类型

  |  类型   |        长度         |      备注      |
  | :-----: | :-----------------: | :------------: |
  | STRING  |         --          |     字符串     |
  | VARCHAR | 字符数范围1 - 65535 | 长度不定字符串 |
  |  CHAR   |  最大的字符数：255  | 长度固定字符串 |

- 其他类型

  |  类型   | 长度 |        备注         |
  | :-----: | :--: | :-----------------: |
  | BOOLEAN |  --  | 布尔类型 TRUE/FALSE |
  | BINARY  |  --  |      字节序列       |



#### 特殊函数

- 窗口函数

  - row_numebr()：不考虑并列情况

    排序示例：1，2，3，4 

  - dense_rank()：并列时不占据位置

    排序示例：1，1，1，2 

  - rank()：并列时占据位置

    排序示例：1，1，1，4

  - 示例：

    ```sql
    select *,row_number() over(partition by A order by B) rn  from testdb.employee where rn=1;
    ```

- 转换函数

  ```sql
  select substr(regexp_replace('2022-10-29 14:49','-',''),1,8);
  
  select regexp_replace('男性','性','');
  
  select split("浙A_99999","_"); 
  
  select split("浙A_99999","_")[1]; 
  
  # 将字符串值转换为整数值
  select cast(substr(regexp_replace('2022-10-29 14:49','-',''),1,8) as bigint) ;
  ```

- 常用工具：

  - union all
  - case when 
  - distinct：hive中使用distinct必须在select的最前面，不能在distinct的前面加列名，否则会报错。可以作用于单列，也可以作用于多列。进行统计：select count(distinct name) from A;





















- 条件

  ```sql
  where a.n_scene_id in ('30101002','30101003','30101006') and a.n_scene_id<>'30103002' and  a.certi_nbr is not null and a.certi_type_id is not null;
  ```

  转义字符

- 转换

  ```sql
  select 
  case when a.prd_inst_stas_id in('120000','120002','120005') then 4001
       when a.prd_inst_stas_id ='110000' then 4002
       when a.prd_inst_stas_id ='150000' then 4003
       when a.prd_inst_stas_id ='130000' then 4004
       when a.prd_inst_stas_id <>'100000' then 4000
       else 0 end scene_code,
  row_number() over(partition by a.prd_inst_id order by a.scene_code desc) rd
  where rd = 1;
  ```

  

- 分组排序

  ```sql
  select *
  from (select  b.*,row_number() over(partition by b.prd_inst_id,b.service_nbr,b.latn_id,b.day,b.ofr_id order by b.dev_code) rn 
  			from eda.tb_b_ft_blackcow_day b 
  			where b.day=${day_num} and b.day_id=${day_id} and b.latn_id=${latn_id} and b.net_num=1 and b.dev_num=1 ) a
  where  a.rn=1 
  ```

  

- case when 

  ```shell
  case when d.pre_rule_type_id='1' then b.sum_chrg_level-nvl(cast(c.rel_chrg_level as double),0)-nvl(cast(d.pre_chrg as double),0)
             else b.sum_chrg_level-nvl(cast(d.pre_chrg as double),0) end sum_chrg_level
  ```

  NVL(expr1,expr2) :如果expr1为NULL，返回值为 expr2，否则返回expr1。

  

  

