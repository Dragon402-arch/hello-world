## Concurrency 并发

[讲解](https://realpython.com/python-concurrency/)

### 并发概念

在Python中，同时发生的事情被称为不同的名称（线程thread，任务task，进程process），但在高层次上，它们都指的是按顺序运行的指令序列。实际上只有多进程（multiprocessing）真正做到了在同一时刻执行了不同的指令，threading 和 asyncio都运行在单个进程内，在同一时刻都只能执行一个指令，但是它们可以通过**分时交替**执行不同的指令加快了指令的执行，即使它们不能真正做到同一时刻执行不同的指令，仍然可以将其称为并发。（注意：Python中的多线程和Java中的多线程非常不同）

 `threading` 与 `asyncio` 在 threads or tasks的交替执行时存在较大差异：

- threading对应着抢占式多任务（Pre-emptive multitasking）
- asyncio对应着协作式多任务（Cooperative multitasking）

### 并发使用场景

#### 1.CPU-bound and I/O-bound.

> I/O-bound problems cause your program to slow down because it frequently must wait for input/output (I/O) from some external resource. They arise frequently when your program is working with things that are much slower than your CPU.The slow things your program will interact with most frequently are the **file system and network connections**.
>
> I/O受限问题会导致你的程序运行减速，因为其必须频繁地等待一些外部资源的输入与输出。当您的程序处理比您的CPU慢得多的东西时，等待会经常出现。你的程序与其进行交互的最频繁的慢东西就是文件系统与网络连接。
>
> On the flip side, there are classes of programs that do significant computation without talking to the network or accessing a file. These are the CPU-bound programs, because the resource limiting the speed of your program is the CPU, not the network or the file system.
>
> 另一方面，有一些程序可以在不与网络通信或访问文件的情况下进行大量计算。这些是CPU-bound的程序，因为限制程序运行速度的资源是CPU，而不是网络或文件系统。

总结：

| I/O-Bound                                                    | CPU-Bound                                                    |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| Your program spends most of its time talking to a slow device, like a network connection, a hard drive, or a printer. | You program spends most of its time doing CPU operations.    |
| Speeding it up involves overlapping the times spent waiting for these devices. | Speeding it up involves finding ways to do more computations in the same amount of time. |

#### 2.解决I/O-Bound问题

##### 2.1 同步版本

同步版本（Synchronous Version），也就是串行版本

```python
import time

import requests


def download_site(url, session):
    with session.get(url) as response:
        print(f"Read {len(response.content)} from {url}")


def download_all_sites(sites):
    with requests.Session() as session:
        for url in sites:
            download_site(url, session)


if __name__ == "__main__":
    sites = [
                "https://realpython.com/python-concurrency/",
                "https://www.baidu.com",
            ] * 20
    start_time = time.time()
    download_all_sites(sites)
    duration = time.time() - start_time
    print(f"Downloaded {len(sites)} in {duration} seconds")

```

##### 2.2 threading 并发版本

```python
#  -*- coding: utf-8 -*-
import threading
import time
from concurrent.futures import ThreadPoolExecutor

import requests

thread_local = threading.local()


def get_session():
    if not hasattr(thread_local, "session"):
        thread_local.session = requests.Session()
    return thread_local.session


def download_site(url):
    # Unfortunately requests.Session() is not thread-safe. you need a separate Session for each thread.
    session = get_session()
    with session.get(url) as response:
        print(f"Read {len(response.content)} from {url}")


def download_all_sites(sites):
    with ThreadPoolExecutor(max_workers=5) as executor:
        executor.map(download_site, sites)


if __name__ == "__main__":
    sites = [
                "https://realpython.com/python-concurrency/",
                "https://www.baidu.com",
            ] * 20
    start_time = time.time()
    download_all_sites(sites)
    duration = time.time() - start_time
    print(f"Downloaded {len(sites)} in {duration} seconds")

```

注意：使用多线程并发加速时可能会因为 thread-safe 问题出现 bug

##### 2.3 asyncio 并发版本

- event loop（事件循环）：controls how and when each task gets run.

  > An important point of asyncio is that the tasks never give up control without intentionally doing so. They never get interrupted in the middle of an operation. This allows us to share resources a bit more easily in asyncio than in threading. You don t have to worry about making your code **thread-safe**.
  >
  > asyncio的一个重要之处在于，任务永远不会放弃控制权，除非有意这样做。他们在行动中从不被打断。这使得我们在asyncio中比在线程中更容易地共享资源。您不必担心使代码线程安全。

- **async and await**

  - await : allows the task to hand control back to the event loop.允许任务将控制权交还给事件循环

    When your code awaits a function call, it’s a signal that the call is likely to be something that takes a while and that the task should give up control.

  - async：使用 `async def func():    `  该方式定义的函数前带有 async 表明函数内部会使用 await。

    any function that calls `await` needs to be marked with `async`

  ```python
  import asyncio
  import time
  import aiohttp
  
  
  async def download_site(session, url):
      async with session.get(url) as response:
          print("Read {0} from {1}".format(response.content_length, url))
  
  
  async def download_all_sites(sites):
      # You can share the session across all tasks, so the session is created here as a context manager.
      # The tasks can share the session because they are all running on the same thread.
      async with aiohttp.ClientSession() as session:
          tasks = []
          for url in sites:
              # Wrap a coroutine or an awaitable in a future.启动任务
              # task = asyncio.create_task(download_site(session, url))
              task = asyncio.ensure_future(download_site(session, url))
              tasks.append(task)
          await asyncio.gather(*tasks, return_exceptions=True)
  
  
  if __name__ == "__main__":
      sites = [
                  "https://www.baidu.com",
                  "https://realpython.com/python-concurrency/",
              ] * 20
      start_time = time.time()
      # python3.7以下运行
      # asyncio.get_event_loop().run_until_complete(download_all_sites(sites))
      # python3.7及以上运行
      asyncio.run(download_all_sites(sites))
      duration = time.time() - start_time
      print(f"Downloaded {len(sites)} in {duration} seconds")
  
  ```
  
   总结：One of the cool advantages of `asyncio` is that it scales far better than `threading`. Each task takes far fewer resources and less time to create than a thread, so creating and running more of them works well. 
  
  与创建一个线程相比，创建每个任务所需的资源和时间要少得多，因此创建和运行更多的任务效果很好。
  
  Another, more subtle, issue is that all of the advantages of cooperative multitasking get thrown away if one of the tasks doesn’t cooperate. A minor mistake in code can cause a task to run off and hold the processor for a long time, starving other tasks that need running. There is no way for the event loop to break in if a task does not hand control back to it.
  
  另一个更微妙的问题是，如果其中一个任务不合作，那么合作式多任务的所有优势都会被抛弃。代码中的一个小错误可能会导致一个任务关闭并长时间占用处理器，使其他需要运行的任务无法运行。如果任务没有将控制权交还给事件循环，则无法中断事件循环。

##### 2.4 multiprocessing 版本

由于GIL（Global Interpreter Lock，全局解释器锁）的存在，导致synchronous, `threading`, and `asyncio`三个版本的程序都只能使用一个CPU核（CPU core）启动一个进程运行程序，而近年来生产的电脑多数情况下会有4个及以上CPU核，因此多数计算资源是闲置的。而multiprocessing则是真正使用多个CPU核运行程序，每个进程中创建一个单独的python解释器，更充分利用计算资源。

```python
#  -*- coding: utf-8 -*-
import multiprocessing
import time

import requests

session = None


def set_global_session():
    global session
    if not session:
        session = requests.Session()


def download_site(url):
    with session.get(url) as response:
        name = multiprocessing.current_process().name
        print(f"{name}:Read {len(response.content)} from {url}")


def download_all_sites(sites):
    #  By default, multiprocessing.Pool() will determine the number of CPUs in your computer and match process num 默认情况下会根据你电脑CPU核数来确定开启的进程数，这通常是最佳选择。
    with multiprocessing.Pool(initializer=set_global_session) as pool:
        # 为每个进程都创建了一个session
        pool.map(download_site, sites)


if __name__ == "__main__":
    sites = [
                "https://www.baidu.com",
                "https://realpython.com/python-concurrency/",
            ] * 20
    start_time = time.time()
    download_all_sites(sites)
    duration = time.time() - start_time
    print(f"Downloaded {len(sites)} in {duration} seconds")

```

#### 3. 解决CPU-Bound问题

```python
#  -*- coding: utf-8 -*-
import multiprocessing
import time


def cpu_bound(number):
    return sum(i * i for i in range(number))


def find_sums(numbers, use_multi_process=False):
    if use_multi_process:
        with multiprocessing.Pool() as pool:
            pool.map(cpu_bound, numbers)
    else:
        for number in numbers:
            cpu_bound(number)


if __name__ == "__main__":
    numbers = [5_000_000 + x for x in range(20)]

    start_time = time.time()
    find_sums(numbers,use_multi_process=False)
    duration = time.time() - start_time
    print(f"Duration {duration} seconds")

```

#### 4. python中并发类型

- `threading`
- `asyncio`
- `multiprocessing`

- 并发（Concurrency）：并发的目标是当一个任务被迫等待外部资源时，通过在任务之间进行切换来防止任务相互阻塞。一个常见的例子是完成网络请求。原始的做法是发起一个请求，等待它完成，然后再发起下一个请求，……。并发方法是一次发起所有请求，然后在它们得到响应时在它们之间进行切换。通过并发，可以降低等待响应所花费的总时间。

  