- **并发**（concurrency）：多个任务同时进行，但在具体的同一时刻只有一个任务在进行。
  - 线程（thread）
  - 进程（process）
    - 多进程（multiprocessing）
    - 单进程
  - 任务（task）
    - 多任务
      - 竞争式多任务（pre-emptive multitasking）：threading
      - 协作式多任务（cooperative multitasking）：asyncio
- **并行**（Parallelism）：多个任务在同一时刻、同时运行。
  - 多进程（multiprocessing）：多核CPU，每个进程都在自己的Python解释器中运行。
  - 进程：结束进程，杀死进程

`ThreadPoolExecutor`，this object is going to create a pool of threads, each of which can run concurrently. Finally, the `Executor` is the part that’s going to control how and when each of the threads in the pool will run. It will execute the request in the pool.



The standard library implements `ThreadPoolExecutor` as a `context manager` so you can use the `with` syntax to manage creating and freeing the pool of `Threads`.

The end of the `with` block causes the `ThreadPoolExecutor` to do a `.join()` on each of the threads in the pool. It is *strongly* recommended that you use `ThreadPoolExecutor` as a context manager when you can so that you never forget to `.join()` the threads.

- 线程安全：

  Because the operating system is in control of when your task gets interrupted and another task starts, any data that is shared between the threads needs to be protected, or **thread-safe**. Unfortunately `requests.Session()` is not **thread-safe**.

  由于操作系统可以控制一个任务中断和另一个任务启动的时间，因此需要保护线程之间共享的任何数据，或者说是线程安全。

  There are several strategies for **making data accesses thread-safe** depending on what the data is and how you’re using it. **One of them is to use thread-safe data structures like `Queue` from Python’s `queue` module.**

  These objects use low-level primitives like `threading.Lock` to ensure that **only one thread can access a block of code or a bit of memory at the same time.** You are using this strategy indirectly by way of the `ThreadPoolExecutor` object.

  **Another strategy to use here is something called thread local storage（线程本地存储）**. `threading.local()` creates an object that looks like a global but is specific to each individual thread. 

  多线程中使用的线程数量增加，可以降低任务处理时间，但是当线程数量超过一定值时，创建和销毁线程额外花费的时间就会抵消掉节省下的时间。

- 

- 理解

  - 先创建一个进程，然后该进程中再创建一个线程，在程序执行过程中进程提供资源（如内存空间），线程是真正工作的单位，进程是为线程提供资源的单位。

    - 工厂    车间    工人
    - 任务     进程   线程  （程序         进程          线程）

  - CPyhton解释器规定在一个进程中同一时刻只能有一个线程被CPU调用。

  - GIL （Global Interpreter Lock GIL）全局解释器锁

    - 主线程
    - 子线程

    ![image-20211222075910338](C:\Users\千江映月\AppData\Roaming\Typora\typora-user-images\image-20211222075910338.png)

- 笔记

  - **进程是操作系统分配资源的最小单元,线程是操作系统调度的最小单元。**
  - 线程
  - 阻塞 
  - 死锁
  - 主线程
  - 子线程
  - 计算机资源可以分为：计算资源和存储资源
    - **计算资源**是操作系统来分配的，也就是常说的操作系统的调度模块
    - **存储资源**就是内存，磁盘这些存储设备的资源

- 函数的递归调用是通过栈（stack）数据结构实现的，

  - 单线程（single-threaded process）：一份code、data、files，一份寄存器（registers），一份栈（stack）
    - 寄存器：控制代码运行进度
    - 栈：控制代码运行状态

  - 多线程（multi-threaded process）：一份code、data、files，每个线程都有属于自己的寄存器（registers）和栈（stack）
    - 每个线程在单独配置寄存器和栈之后，线程就有了独立运行和控制运行进度的能力。
    - 多线程的运行方式常称为非阻塞式的，异步的。
    - 同步是指在单线程中，若要完成多个任务，只要在一个任务完成之后，才可以开始下一个任务，此时将这两个任务称为是同步的，也称为阻塞式的，每个任务在执行时都是独占线程的。
    - CPU调度多线程的一个典型方式是分时复用，时间片。
    - 并发：在一段时间内，宏观上有多个程序同时执行，微观上仍是分时交替执行。全局CPU是串行的，而每个线程都是在不断向前执行的，具体到某一个时刻是只有一个线程在执行的，而在一段时间段内可以观察到多个线程都是在向前执行的，由此实现了多线程执行，达到了齐头并进的效果。对于每个线程而言，其都有属于自己的寄存器和栈，并严格按照时间片的先后顺序执行，还是阻塞式的。
    - 多线程中，每个线程执行任务所花费的时间可能不同的，可能某个线程执行较快，很快进行了下一个任务。
    - 系统级别的线程和Python中的线程是不同的，程序级的多线程可能共用一个系统级的线程。

  - 线程池（Thread Pool)：事先准备好的几个线程，当想要使用一个线程时，并不是新建一个线程，用完再删掉，而是在线程池中申请使用其中的一个，这种方式避免了额外的资源开销（不要新建和释放），

    - 任务队列（Task Queue ）

    - 任务调度（Task schedule）觉得哪些任务优先运行，从任务队列中取出一个任务。

    - 完成任务（Completed Tasks) :执行结果

      ![1920px-Thread_pool.svg](D:\Typora\Python\1920px-Thread_pool.svg.png)

    - CPU密集型：多进程方式更好，对于每一个进程，至少会分配一个系统级的线程，这个进程就可以独占一个系统级的线程。运算密集型，需要大量运算资源时，使用多进程方式可以更有效地利用系统级资源。

    - I/O密集型：

    - 先找到一个能运行的，再小修小改，然后再回头深挖一下，应用为主，先把它用起来。

      ```python
      import concurrent.futures
      import urllib.request
      
      URLS = ['http://www.foxnews.com/',
              'http://www.cnn.com/',
              'http://europe.wsj.com/',
              'http://www.bbc.co.uk/',
              'http://some-made-up-domain.com/']
      
      # Retrieve a single page and report the URL and contents
      def load_url(url, timeout):
          with urllib.request.urlopen(url, timeout=timeout) as conn:
              return conn.read()
      
      # We can use a with statement to ensure threads are cleaned up promptly
      with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
          # Start the load operations and mark each future with its URL
          future_to_url = {executor.submit(load_url, url, 60): url for url in URLS}
          for future in concurrent.futures.as_completed(future_to_url): # 遍历一个生成器
              url = future_to_url[future]
              try:
                  data = future.result()
              except Exception as exc:
                  print('%r generated an exception: %s' % (url, exc))
              else:
                  print('%r page is %d bytes' % (url, len(data)))
      ```

    - 多线程并没有很好地利用利用系统的

    - 线程状态：

      - 就绪（等待）
      - 阻塞
      - 运行
    
    - 若计算机只有一个单核CPU，也就是一次只能执行一个线程，也就需要对每个线程轮流执行，每个线程每次单个计算的时间称为一个CPU时间片，对于线程而言，存在等待CPU的时间，称为就绪状态，开始执行时转变为**运行状态**。假如程序向硬盘发送访问请求，然后等待，此时CPU就变成空转了，此时线程变为**阻塞状态**，CPU转而执行其他线程。等到硬盘的数据回复 ，线程从阻塞状态转变为**就绪状态**。
    
    - 时间片轮转，若存在多个CPU，确实可以使得多个线程真正地并行计算，但是往往线程会很多，仍然需要时间片轮转，为了进行简化，CPU在内核中会为每个线程提供各自虚拟的CPU，每个线程可以认为自己一直独占CPU，因而不需要考虑时间片轮转的问题。
    
    - 进程可以占用系统，文件，内存等资源，不同进程不共享资源，而线程不占用资源，线程可以使用进程的资源，同一进程内不同线程共享资源
    
    - There are two types of concurrent programming in computing: multithreading and multiprocessing.Each process or thread runs in a single core of a multicore processor.
    
      - 进程：
    
        - Each process can have multiple threads. 
        - The other processes created by the main process are called child process
    
        - The OS helps you to create, schedule, and terminates the processes which is used by CPU. 创建、调度、终止杀死
        - If one process is blocked then it will not effect the execution of other process. 
        - Communication among processes is quite costly since they don’t share memory of any kind.
    
      - 线程：
    
        - Thread is an execution unit that is part of a process. A process can have multiple threads, all executing at the same time. It is a unit of execution in concurrent programming. A thread is lightweight and can be managed independently by a scheduler.Multiple threads share information like data, code, files, etc.
        - A thread have 3 states: running, ready, and blocked. 一个线程存在三种状态：运行、就绪、阻塞。
    
        
    
        - A thread can do anything a process can do. The main difference here is memory sharing. Threads are usually used for performing small tasks.When it comes to memory sharing, a thread shares the same memory with its creator process. In other words, threads can read and write the same data structures and variables as their creators.Communication among threads is also easy to achieve since they share the same address space when they are within the same process.
        - 为避免线程间相互竞争，必要时需要使用线程锁。

