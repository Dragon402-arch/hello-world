- 介绍一下常用的大模型，ChatGLM1/2、Baichuan、Llama
- 介绍一下指令微调的过程
  - 通用大模型效果评测部分不懂
- 介绍一下FlashAttention
- 介绍一下deepspeed的三个阶段
- 介绍一下deepspeed的前向传播和反向传播过程
- 介绍一下混合精度训练
- 介绍一下文本分块的实现方案，模型实现，
  - 你的分块规则
  - 文本分块模型实现方案、如何评价效果



| 组件       | ChatGLM1                    | ChatGLM2                                     |
| ---------- | --------------------------- | -------------------------------------------- |
| 模型类型   | prefix-lm                   | decoder-only                                 |
| 激活函数   | geglu                       | swiglu                                       |
| 中间层维度 | 4h                          | 非标准4h，3.34h                              |
| 位置编码   | rope                        | 部分rope                                     |
| 注意力机制 | 标准注意力机制              | 分组注意力机制和FlashAttention               |
| 流式对话   | yield response, new_history | yield response, new_history, past_key_values |
|            |                             |                                              |











- Doc2EDAG模型原理
- 文本分块拆分规则
  - 优化现有拆分规则
  - 有没有最大、最小长度限制
  - 文本分块模型具体实现逻辑
- 推理加速
- 多并发场景实现
- 大模型幻觉问题，如何处理
  - 大模型在专业领域的知识储备不足时，会输出一些违背常识的错误信息，此时可以增强模型领域知识储备的完备性
  - 人类提问方式，模型存在理解偏差，给出答非所问的回答。丰富提问方式以及生成对齐人类意图的回答。


- RAG
  - 检索增强生成(RAG)来**扩展语言模型的知识范围**
  - 其中,sentence-transformers模型对文本编码,Pinecone用于构建向量索引。当询问有关LLaMA2的问题时,仅用LLaMA2无法给出正确答案,但联合RAG可以检索到相关文档,为模型提供上下文,使其产生知识丰富、正确的回答。RAG允许语言模型访问外部信息,大大扩展其应用范围。相比独立模型仅依靠训练知识,RAG可以处理更多现实中的问题。本视频介绍了实现RAG的具体流程,并直观展示了其效果。RAG是增强语言模型的重要手段之一

大模型架构

- 需要有记忆，history

- OpenAI 对话示例：

  ```shell
  system
  user
  assistant
  ```

- 使用模板改写提示做增强：模板可以增强和改变回答效果

- 外部工具

  - 将用户问题和外部工具的描述一起输入给大模型，由模型判断调用哪个工具
  - 系统将问题和一个查询天气的API一起输入到模型中，模型判断是否需要调用天气API，如果需要就会返回调用天气API的参数，agent会解析模型返回的参数，并去调用天气API、然后将API返回的结果输入到大模型中，由大模型给出最终回答。

- 外部知识库

- 









































​	
