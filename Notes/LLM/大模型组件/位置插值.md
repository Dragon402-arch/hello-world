#### Position Interpolation

位置插值计算公式：
$$
f^′(x,m) = f(x,\frac{mL}{L^′})
$$
其中 $L^′$ 表示实际序列长度，比如4096，$L$ 表示上下文窗口长度，如2048。





其中，ChatGLM2-6B-32K 在 ChatGLM2-6B 的基础上进一步强化了对于长文本的理解能力，能够更好的处理最多32K长度的上下文。具体地，我们基于位置插值（Positional Interpolation）的方法对位置编码进行了更新，并在对话阶段使用 32K 的上下文长度训练。 

长文本理解
我们引入了NTK插值、窗口注意力、LogN注意力缩放等技术来提升模型的上下文长度并突破训练序列长度的限制。我们的模型已经突破8K的序列长度。通过arXiv数据集上的语言模型实验，我们发现Qwen-7B能够在长序列的设置下取得不错的表现。





扩展大模型的上下文长度

- 基于位置插值的扩展方法 + 增量训练适配（4k ——> 16k）

- 基于NTK的扩展方法（16k ——> 32k）

  

#### NTK扩展

基于 Neural Tangent Kernel（NTK）的上下文长度扩展技术。

• **无需进一步训练**，通过改变RoPE的base， “拉伸”位置编码来达到延长上下文长度

• 优点：**模型无需进一步训练，只需在推理阶段对RoPE的超参进行修改**

• 缺点：**外推长度有限**，通常在3x内与原生上下文长度达到可比PPL

• 我们设计了一种**自适应经验公式**，通常无需针对不同的上下文长度手动设置超参
$$
\large 10000^{−2i/d} \text{ ——>} (10000\alpha ^{d/(d−2 )})^{−2i/d}
$$

#### 基于位置插值（PI）的上下文扩展技术

• 主要思想是在现有的RoPE基础上进行插值，使得位置编码数据点增加，从而支持更长的上下文

• 优点：相比NTK方法可以支持更长的上下文

• 缺点：插值之后通常需要经过一定量的训练以重新适配新的位置编码









BERT模型中位置表示和单词的向量表示为什么可以相加？





亮总，感谢一下您在公司对我的关照，上次和您交流之后，我也反复地思考过，我最终认为新的机会更符合我的兴趣以及职业发展方向，目前需要交接的内容我已经整理好了，后续交接的时候我都会积极配合的，您看可否帮我走下OA的审批流程，谢谢。

